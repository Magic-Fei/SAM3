#!/usr/bin/env python
"""
Batch inference script for SAM3 image model with hardcoded paths/settings.
Edit the constants below to match your environment, then run:

    python tools/batch_inference.py
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Dict, Iterable, List, Optional

import cv2
import numpy as np
import torch
from PIL import Image, ImageDraw
from tqdm import tqdm

from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor

# ============================================================================
# Hardcoded configuration
# ============================================================================
# æ ‡å‡†æ¨¡å‹çš„checkpointï¼ˆå·²ç»è®­ç»ƒå¥½ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼‰
CHECKPOINT_PATH = Path(r"D:\qianpf\code\sam3-main\experiments_jiaodai\checkpoints\checkpoint_fp.pt")

INPUT_DIR = Path(r"D:\qianpf\data\auxx\images")  # folder containing source images
OUTPUT_DIR = Path(r"D:\qianpf\data\auxx\res")
PROMPT = "visual"  # e.g. "visual", "car", "guajia", etc.
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SCORE_THRESHOLD = 0.5  # é™ä½é˜ˆå€¼ä»¥çœ‹åˆ°æ›´å¤šæ£€æµ‹ç»“æœ
USE_FP16 = False # å¦‚æœåŠ è½½çš„æ˜¯ FP16 æ¨¡å‹ï¼Œè®¾ç½®ä¸º True

# ä¿å­˜é…ç½®
SAVE_MASKS = False  # æ˜¯å¦ä¿å­˜ masks å›¾åƒï¼ˆé»˜è®¤å…³é—­ï¼‰
SAVE_OVERLAYS = True  # æ˜¯å¦ä¿å­˜ overlays å¯è§†åŒ–å›¾åƒï¼ˆé»˜è®¤å…³é—­ï¼‰

# Labelme è½¬æ¢é…ç½®
CONVERT_TO_LABELME = False # æ˜¯å¦è½¬æ¢ä¸º labelme æ ¼å¼
LABELME_ANNOTATION_TYPE = "segmentation"  # æ ‡æ³¨ç±»å‹: "segmentation"ï¼ˆåˆ†å‰²ï¼‰æˆ– "detection"ï¼ˆç›®æ ‡æ£€æµ‹ï¼‰

# å¤šç±»åˆ«é…ç½®ï¼ˆå¦‚æœè®­ç»ƒäº†å¤šç±»åˆ«æ¨¡å‹ï¼‰
# æ–¹å¼1: ä½¿ç”¨ç±»åˆ«åˆ—è¡¨ï¼ˆæ¨èï¼‰- ä¼šå¾ªç¯åˆ†é…ç±»åˆ«æ ‡ç­¾
LABELME_CLASS_LABELS = ["guajia","insulatingTube_fore", "jiaodai"]  # ç±»åˆ«åç§°åˆ—è¡¨ï¼Œå¿…é¡»ä¸è®­ç»ƒæ—¶çš„ç±»åˆ«æ•°é‡ä¸€

# æ–¹å¼2: ä½¿ç”¨å•ä¸ªç±»åˆ«æ ‡ç­¾ï¼ˆå•ç±»åˆ«æˆ–æ‰€æœ‰æ£€æµ‹ç»“æœä½¿ç”¨åŒä¸€æ ‡ç­¾ï¼‰
# LABELME_CLASS_LABEL = "1"  # å¦‚æœä½¿ç”¨æ­¤æ–¹å¼ï¼Œæ³¨é‡Šæ‰ä¸Šé¢çš„ LABELME_CLASS_LABELS

# ç±»åˆ«åˆ†é…ç­–ç•¥ï¼ˆå½“ä½¿ç”¨ LABELME_CLASS_LABELS æ—¶ï¼‰
LABELME_CLASS_ASSIGNMENT = "by_area"  # "round_robin"ï¼ˆå¾ªç¯åˆ†é…ï¼‰ã€"by_score"ï¼ˆæŒ‰ç½®ä¿¡åº¦åˆ†é…ï¼‰æˆ– "by_area"ï¼ˆæŒ‰é¢ç§¯åˆ†ç»„ï¼‰
# "round_robin": æŒ‰é¡ºåºå¾ªç¯åˆ†é…ç±»åˆ«ï¼ˆç¬¬1ä¸ªæ£€æµ‹=class1, ç¬¬2ä¸ª=class2, ç¬¬3ä¸ª=class3, ç¬¬4ä¸ª=class1...ï¼‰
# "by_score": æ ¹æ®ç½®ä¿¡åº¦åˆ†æ•°åˆ†é…ï¼ˆéœ€è¦è®¾ç½® LABELME_CLASS_SCORE_THRESHOLDSï¼‰
# "by_area": æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åºï¼Œé¢ç§¯ç›¸è¿‘çš„ï¼ˆç›¸å·®åœ¨ AREA_TOLERANCE ä»¥å†…ï¼‰å½’ä¸ºåŒä¸€ç±»åˆ«ï¼Œæ¯ç»„åˆ†é…ä¸€ä¸ªç±»åˆ«ï¼ˆclass1, class2, class3...ï¼‰
LABELME_CLASS_SCORE_THRESHOLDS = [0.5, 0.5, 0.5]  # æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä»…ç”¨äº "by_score" æ¨¡å¼ï¼‰
AREA_TOLERANCE = 0.8  # é¢ç§¯å®¹å·®ï¼ˆ50%ï¼‰ï¼Œç”¨äº "by_area" æ¨¡å¼ï¼Œé¢ç§¯ç›¸å·®åœ¨æ­¤èŒƒå›´å†…çš„å½’ä¸ºåŒä¸€ç±»åˆ«


def load_model(ckpt_path: Path, device: torch.device) -> Sam3Processor:
    """Load trained SAM3 model from checkpoint."""
    print(f"Loading checkpoint from: {ckpt_path}")
    
    # Build empty model structure
    print("ğŸš€ Building standard SAM3 model...")
    model = build_sam3_image_model(
        checkpoint_path=None,
        load_from_HF=False,
        enable_segmentation=True,
        device=str(device),
        eval_mode=True,
    )
    
    # Load checkpoint file
    checkpoint = torch.load(ckpt_path, map_location=device)
    
    # Extract state_dict from different checkpoint formats
    if "model" in checkpoint:
        state_dict = checkpoint["model"]
        print(f"âœ“ Loaded checkpoint (epoch: {checkpoint.get('epoch', 'unknown')})")
    elif "state_dict" in checkpoint:
        state_dict = checkpoint["state_dict"]
        print("âœ“ Loaded checkpoint (state_dict format)")
    else:
        state_dict = checkpoint
        print("âœ“ Loaded checkpoint (raw weights)")
    
    # Load weights into model
    missing, unexpected = model.load_state_dict(state_dict, strict=False)
    
    if missing:
        print(f"âš  Missing keys ({len(missing)} keys):")
        for key in missing[:5]:  # Show first 5
            print(f"  - {key}")
        if len(missing) > 5:
            print(f"  ... and {len(missing) - 5} more")
    
    if unexpected:
        print(f"âš  Unexpected keys ({len(unexpected)} keys):")
        for key in unexpected[:5]:  # Show first 5
            print(f"  - {key}")
        if len(unexpected) > 5:
            print(f"  ... and {len(unexpected) - 5} more")
    
    if not missing and not unexpected:
        print("âœ“ All weights loaded successfully!")
    
    # å¦‚æœä½¿ç”¨ FP16 æ¨¡å‹
    if USE_FP16:
        if device.type == "cuda":
            model = model.half()
            print("âœ“ Using FP16 (half precision)")
        else:
            print("âš  FP16 only supported on CUDA, using FP32 on CPU")
    
    model.eval()
    processor = Sam3Processor(model, device=str(device))
    print("âœ“ Model ready for inference\n")
    return processor


def iter_images(folder: Path) -> Iterable[Path]:
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff", ".webp"}
    for path in sorted(folder.rglob("*")):
        if path.suffix.lower() in exts:
            yield path


def blend_masks(image: Image.Image, masks: np.ndarray, colors: np.ndarray, alpha: float = 0.5) -> Image.Image:
    """
    Blend colored masks on top of the original image.
    """
    base = np.array(image).astype(np.float32)
    overlay = base.copy()

    for color, mask in zip(colors, masks):
        if mask.ndim == 3:
            mask = np.squeeze(mask, axis=0)
        mask_bin = mask > 0.5
        if not mask_bin.any():
            continue
        color_px = (color * 255).astype(np.float32)
        overlay[mask_bin] = overlay[mask_bin] * (1 - alpha) + color_px * alpha

    return Image.fromarray(overlay.astype(np.uint8))


def save_masks(masks: np.ndarray, out_dir: Path, stem: str):
    """Save each mask as a separate binary image."""
    mask_dir = out_dir / "masks"
    mask_dir.mkdir(parents=True, exist_ok=True)
    for idx, mask in enumerate(masks):
        # Ensure mask is 2D (H, W)
        mask = np.squeeze(mask)
        if mask.ndim != 2:
            print(f"[WARN] Unexpected mask shape {mask.shape}, skipping...")
            continue
        # Convert to binary image
        mask_binary = (mask > 0.5).astype(np.uint8) * 255
        mask_img = Image.fromarray(mask_binary, mode='L')
        mask_img.save(mask_dir / f"{stem}_mask_{idx:02d}.png")


def run_inference(
    processor: Sam3Processor,
    image_path: Path,
    prompt: str,
    score_threshold: float,
) -> Dict[str, torch.Tensor]:
    image = Image.open(image_path).convert("RGB")
    
    # å¦‚æœä½¿ç”¨ FP16ï¼Œéœ€è¦ä½¿ç”¨ autocast åŒ…è£¹æ¨ç†è¿‡ç¨‹
    if USE_FP16 and DEVICE.type == "cuda":
        with torch.cuda.amp.autocast(dtype=torch.float16):
            state = processor.set_image(image)
            outputs = processor.set_text_prompt(state=state, prompt=prompt)
    else:
        state = processor.set_image(image)
        outputs = processor.set_text_prompt(state=state, prompt=prompt)
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŸå§‹æ£€æµ‹ç»“æœ
    raw_scores = outputs["scores"].cpu().numpy()
    print(f"  {image_path.name}: æ£€æµ‹åˆ° {len(raw_scores)} ä¸ªç‰©ä½“")
    if len(raw_scores) > 0:
        print(f"    åˆ†æ•°èŒƒå›´: [{raw_scores.min():.3f}, {raw_scores.max():.3f}]")
        print(f"    å¹³å‡åˆ†æ•°: {raw_scores.mean():.3f}")
    
    # Filter by confidence
    scores = outputs["scores"]
    keep = scores >= score_threshold
    num_kept = keep.sum().item()
    print(f"    é˜ˆå€¼ {score_threshold} åä¿ç•™: {num_kept} ä¸ª")
    
    for key in ("masks", "boxes", "scores"):
        outputs[key] = outputs[key][keep]
    outputs["image"] = image
    return outputs


def visualize_and_save(image: Image.Image, outputs: Dict[str, torch.Tensor], out_path: Path):
    masks = outputs["masks"].cpu().numpy()
    boxes = outputs["boxes"].cpu().numpy()
    scores = outputs["scores"].cpu().numpy()

    if len(masks) == 0:
        image.save(out_path)
        return

    colors = plt_colormap(len(masks))
    overlay = blend_masks(image, masks, colors)
    draw = ImageDraw.Draw(overlay)
    for color, box, score in zip(colors, boxes, scores):
        x1, y1, x2, y2 = box.tolist()
        rgb = tuple(int(c * 255) for c in color)
        draw.rectangle([x1, y1, x2, y2], outline=rgb, width=2)
        draw.text((x1, max(0, y1 - 12)), f"{score:.2f}", fill=rgb)
    overlay.save(out_path)


def plt_colormap(n: int) -> np.ndarray:
    if n == 0:
        return np.zeros((0, 3))
    cmap = np.linspace(0, 1, n)
    colors = np.stack([np.sin(2 * np.pi * (cmap + shift)) for shift in (0, 0.33, 0.66)], axis=1)
    colors = (colors * 0.5 + 0.5).clip(0, 1)
    return colors


def calculate_mask_area(mask: np.ndarray) -> float:
    """
    è®¡ç®— mask çš„é¢ç§¯ï¼ˆåƒç´ æ•°ï¼‰ã€‚
    
    Args:
        mask: mask æ•°ç»„ (H, W) æˆ– (1, H, W)
    
    Returns:
        é¢ç§¯ï¼ˆåƒç´ æ•°ï¼‰
    """
    if mask.ndim == 3:
        mask = np.squeeze(mask, axis=0)
    if mask.ndim != 2:
        return 0.0
    
    mask_binary = (mask > 0.5).astype(np.uint8)
    area = np.sum(mask_binary)
    return float(area)


def group_by_area(masks: np.ndarray, tolerance: float = 0.3) -> List[List[int]]:
    """
    æ ¹æ®é¢ç§¯å¯¹ mask è¿›è¡Œåˆ†ç»„ï¼Œé¢ç§¯ç›¸å·®åœ¨ toleranceï¼ˆç™¾åˆ†æ¯”ï¼‰ä»¥å†…çš„å½’ä¸ºä¸€ç»„ã€‚
    
    Args:
        masks: mask æ•°ç»„ (N, H, W) æˆ– (N, 1, H, W)
        tolerance: é¢ç§¯å®¹å·®ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œä¾‹å¦‚ 0.3 è¡¨ç¤º 30%
    
    Returns:
        åˆ†ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªç´¢å¼•åˆ—è¡¨ï¼Œè¡¨ç¤ºå±äºåŒä¸€ç»„çš„ mask ç´¢å¼•
    """
    if len(masks) == 0:
        return []
    
    # è®¡ç®—æ¯ä¸ª mask çš„é¢ç§¯
    areas = []
    for i, mask in enumerate(masks):
        area = calculate_mask_area(mask)
        areas.append((i, area))
    
    # æŒ‰é¢ç§¯æ’åº
    areas.sort(key=lambda x: x[1])
    
    # åˆ†ç»„ï¼šé¢ç§¯ç›¸å·®åœ¨ tolerance ä»¥å†…çš„å½’ä¸ºä¸€ç»„
    groups = []
    current_group = [areas[0][0]]  # ç¬¬ä¸€ä¸ª mask çš„ç´¢å¼•
    current_base_area = areas[0][1]
    
    for i in range(1, len(areas)):
        idx, area = areas[i]
        
        # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ç»„çš„åŸºå‡†é¢ç§¯ç›¸å·®åœ¨å®¹å·®èŒƒå›´å†…
        if current_base_area > 0:
            area_diff_ratio = abs(area - current_base_area) / current_base_area
        else:
            area_diff_ratio = float('inf') if area > 0 else 0.0
        
        if area_diff_ratio <= tolerance:
            # å±äºå½“å‰ç»„
            current_group.append(idx)
        else:
            # å¼€å§‹æ–°ç»„
            groups.append(current_group)
            current_group = [idx]
            current_base_area = area
    
    # æ·»åŠ æœ€åä¸€ç»„
    if current_group:
        groups.append(current_group)
    
    return groups


def calculate_box_area(box: np.ndarray) -> float:
    """
    è®¡ç®—è¾¹ç•Œæ¡†çš„é¢ç§¯ã€‚
    
    Args:
        box: è¾¹ç•Œæ¡†æ•°ç»„ [x1, y1, x2, y2]
    
    Returns:
        é¢ç§¯ï¼ˆåƒç´ æ•°ï¼‰
    """
    x1, y1, x2, y2 = box
    width = max(0, x2 - x1)
    height = max(0, y2 - y1)
    return float(width * height)


def group_boxes_by_area(boxes: np.ndarray, tolerance: float = 0.3) -> List[List[int]]:
    """
    æ ¹æ®é¢ç§¯å¯¹è¾¹ç•Œæ¡†è¿›è¡Œåˆ†ç»„ï¼Œé¢ç§¯ç›¸å·®åœ¨ toleranceï¼ˆç™¾åˆ†æ¯”ï¼‰ä»¥å†…çš„å½’ä¸ºä¸€ç»„ã€‚
    
    Args:
        boxes: è¾¹ç•Œæ¡†æ•°ç»„ (N, 4)ï¼Œæ ¼å¼ä¸º [x1, y1, x2, y2]
        tolerance: é¢ç§¯å®¹å·®ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œä¾‹å¦‚ 0.3 è¡¨ç¤º 30%
    
    Returns:
        åˆ†ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªç´¢å¼•åˆ—è¡¨ï¼Œè¡¨ç¤ºå±äºåŒä¸€ç»„çš„è¾¹ç•Œæ¡†ç´¢å¼•
    """
    if len(boxes) == 0:
        return []
    
    # è®¡ç®—æ¯ä¸ªè¾¹ç•Œæ¡†çš„é¢ç§¯
    areas = []
    for i, box in enumerate(boxes):
        area = calculate_box_area(box)
        areas.append((i, area))
    
    # æŒ‰é¢ç§¯æ’åº
    areas.sort(key=lambda x: x[1])
    
    # åˆ†ç»„ï¼šé¢ç§¯ç›¸å·®åœ¨ tolerance ä»¥å†…çš„å½’ä¸ºä¸€ç»„
    groups = []
    current_group = [areas[0][0]]  # ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†çš„ç´¢å¼•
    current_base_area = areas[0][1]
    
    for i in range(1, len(areas)):
        idx, area = areas[i]
        
        # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ç»„çš„åŸºå‡†é¢ç§¯ç›¸å·®åœ¨å®¹å·®èŒƒå›´å†…
        if current_base_area > 0:
            area_diff_ratio = abs(area - current_base_area) / current_base_area
        else:
            area_diff_ratio = float('inf') if area > 0 else 0.0
        
        if area_diff_ratio <= tolerance:
            # å±äºå½“å‰ç»„
            current_group.append(idx)
        else:
            # å¼€å§‹æ–°ç»„
            groups.append(current_group)
            current_group = [idx]
            current_base_area = area
    
    # æ·»åŠ æœ€åä¸€ç»„
    if current_group:
        groups.append(current_group)
    
    return groups


def assign_labels_by_area(
    masks: np.ndarray,
    class_labels: List[str],
    tolerance: float = 0.3,
) -> List[str]:
    """
    æ ¹æ®é¢ç§¯ä»å¤§åˆ°å°æ’åºï¼Œé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ã€‚
    
    Args:
        masks: mask æ•°ç»„ (N, H, W) æˆ– (N, 1, H, W)
        class_labels: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
        tolerance: é¢ç§¯å®¹å·®ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œä¾‹å¦‚ 0.3 è¡¨ç¤º 30%ï¼Œé¢ç§¯ç›¸å·®åœ¨æ­¤èŒƒå›´å†…çš„å½’ä¸ºåŒä¸€ç±»åˆ«
    
    Returns:
        æ¯ä¸ª mask å¯¹åº”çš„ç±»åˆ«æ ‡ç­¾åˆ—è¡¨ï¼ˆé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ï¼‰
    """
    if len(masks) == 0:
        return []
    
    # è®¡ç®—æ¯ä¸ª mask çš„é¢ç§¯
    areas = []
    for i, mask in enumerate(masks):
        area = calculate_mask_area(mask)
        areas.append((i, area))
    
    # æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åº
    areas.sort(key=lambda x: x[1], reverse=True)
    
    # åˆ†ç»„ï¼šé¢ç§¯ç›¸è¿‘çš„ï¼ˆç›¸å·®åœ¨ tolerance ä»¥å†…ï¼‰å½’ä¸ºä¸€ç»„
    groups = []
    if len(areas) > 0:
        current_group = [areas[0][0]]  # ç¬¬ä¸€ä¸ª mask çš„ç´¢å¼•
        current_base_area = areas[0][1]
        
        for i in range(1, len(areas)):
            idx, area = areas[i]
            
            # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ç»„çš„åŸºå‡†é¢ç§¯ç›¸å·®åœ¨å®¹å·®èŒƒå›´å†…
            if current_base_area > 0:
                area_diff_ratio = abs(area - current_base_area) / current_base_area
            else:
                area_diff_ratio = float('inf') if area > 0 else 0.0
            
            if area_diff_ratio <= tolerance:
                # å±äºå½“å‰ç»„ï¼ˆé¢ç§¯ç›¸è¿‘ï¼‰
                current_group.append(idx)
            else:
                # å¼€å§‹æ–°ç»„ï¼ˆé¢ç§¯å·®è·è¾ƒå¤§ï¼‰
                groups.append(current_group)
                current_group = [idx]
                current_base_area = area
        
        # æ·»åŠ æœ€åä¸€ç»„
        if current_group:
            groups.append(current_group)
    
    # ä¸ºæ¯ä¸ª mask åˆ†é…æ ‡ç­¾
    num_masks = len(masks)
    labels = [None] * num_masks
    
    # ä¸ºæ¯ä¸ªç»„åˆ†é…ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ï¼ˆå¾ªç¯ä½¿ç”¨ class1, class2, class3...ï¼‰
    for group_idx, group in enumerate(groups):
        class_label = class_labels[group_idx % len(class_labels)]
        for mask_idx in group:
            labels[mask_idx] = class_label
    
    return labels


def assign_labels_by_box_area(
    boxes: np.ndarray,
    class_labels: List[str],
    tolerance: float = 0.3,
) -> List[str]:
    """
    æ ¹æ®è¾¹ç•Œæ¡†é¢ç§¯ä»å¤§åˆ°å°æ’åºï¼Œé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ã€‚
    
    Args:
        boxes: è¾¹ç•Œæ¡†æ•°ç»„ (N, 4)ï¼Œæ ¼å¼ä¸º [x1, y1, x2, y2]
        class_labels: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
        tolerance: é¢ç§¯å®¹å·®ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œä¾‹å¦‚ 0.3 è¡¨ç¤º 30%ï¼Œé¢ç§¯ç›¸å·®åœ¨æ­¤èŒƒå›´å†…çš„å½’ä¸ºåŒä¸€ç±»åˆ«
    
    Returns:
        æ¯ä¸ªè¾¹ç•Œæ¡†å¯¹åº”çš„ç±»åˆ«æ ‡ç­¾åˆ—è¡¨ï¼ˆé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ï¼‰
    """
    if len(boxes) == 0:
        return []
    
    # è®¡ç®—æ¯ä¸ªè¾¹ç•Œæ¡†çš„é¢ç§¯
    areas = []
    for i, box in enumerate(boxes):
        area = calculate_box_area(box)
        areas.append((i, area))
    
    # æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åº
    areas.sort(key=lambda x: x[1], reverse=True)
    
    # åˆ†ç»„ï¼šé¢ç§¯ç›¸è¿‘çš„ï¼ˆç›¸å·®åœ¨ tolerance ä»¥å†…ï¼‰å½’ä¸ºä¸€ç»„
    groups = []
    if len(areas) > 0:
        current_group = [areas[0][0]]  # ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†çš„ç´¢å¼•
        current_base_area = areas[0][1]
        
        for i in range(1, len(areas)):
            idx, area = areas[i]
            
            # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ç»„çš„åŸºå‡†é¢ç§¯ç›¸å·®åœ¨å®¹å·®èŒƒå›´å†…
            if current_base_area > 0:
                area_diff_ratio = abs(area - current_base_area) / current_base_area
            else:
                area_diff_ratio = float('inf') if area > 0 else 0.0
            
            if area_diff_ratio <= tolerance:
                # å±äºå½“å‰ç»„ï¼ˆé¢ç§¯ç›¸è¿‘ï¼‰
                current_group.append(idx)
            else:
                # å¼€å§‹æ–°ç»„ï¼ˆé¢ç§¯å·®è·è¾ƒå¤§ï¼‰
                groups.append(current_group)
                current_group = [idx]
                current_base_area = area
        
        # æ·»åŠ æœ€åä¸€ç»„
        if current_group:
            groups.append(current_group)
    
    # ä¸ºæ¯ä¸ªè¾¹ç•Œæ¡†åˆ†é…æ ‡ç­¾
    num_boxes = len(boxes)
    labels = [None] * num_boxes
    
    # ä¸ºæ¯ä¸ªç»„åˆ†é…ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ï¼ˆå¾ªç¯ä½¿ç”¨ class1, class2, class3...ï¼‰
    for group_idx, group in enumerate(groups):
        class_label = class_labels[group_idx % len(class_labels)]
        for box_idx in group:
            labels[box_idx] = class_label
    
    return labels


def mask_to_polygon(mask: np.ndarray, epsilon_factor: float = 0.002) -> Optional[List[List[float]]]:
    """
    å°†äºŒå€¼ mask è½¬æ¢ä¸ºå¤šè¾¹å½¢ç‚¹åˆ—è¡¨ã€‚
    
    Args:
        mask: äºŒå€¼ mask æ•°ç»„ (H, W)
        epsilon_factor: å¤šè¾¹å½¢ç®€åŒ–ç³»æ•°ï¼Œè¶Šå¤§ç‚¹æ•°è¶Šå°‘ï¼ˆé»˜è®¤ 0.002ï¼Œçº¦ä¸ºåŸæ¥çš„ä¸€åŠç‚¹æ•°ï¼‰
    
    Returns:
        å¤šè¾¹å½¢ç‚¹åˆ—è¡¨ [[x1, y1], [x2, y2], ...]ï¼Œå¦‚æœ mask ä¸ºç©ºåˆ™è¿”å› None
    """
    # ç¡®ä¿ mask æ˜¯äºŒå€¼çš„
    if mask.ndim != 2:
        mask = np.squeeze(mask)
    if mask.ndim != 2:
        return None
    
    mask_binary = (mask > 0.5).astype(np.uint8) * 255
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    # é€‰æ‹©æœ€å¤§çš„è½®å»“
    largest_contour = max(contours, key=cv2.contourArea)
    
    # ç®€åŒ–è½®å»“ï¼ˆå‡å°‘ç‚¹æ•°ï¼Œepsilon_factor è¶Šå¤§ï¼Œç‚¹æ•°è¶Šå°‘ï¼‰
    epsilon = epsilon_factor * cv2.arcLength(largest_contour, True)
    approx = cv2.approxPolyDP(largest_contour, epsilon, True)
    
    # è½¬æ¢ä¸ºç‚¹åˆ—è¡¨æ ¼å¼ [[x, y], ...]
    polygon = approx.reshape(-1, 2).tolist()
    
    return polygon


def boxes_to_labelme_rectangles(boxes: np.ndarray, label: str) -> List[Dict]:
    """
    å°†è¾¹ç•Œæ¡†è½¬æ¢ä¸º labelme çŸ©å½¢æ ¼å¼ã€‚
    
    Args:
        boxes: è¾¹ç•Œæ¡†æ•°ç»„ (N, 4)ï¼Œæ ¼å¼ä¸º [x1, y1, x2, y2]
        label: ç±»åˆ«æ ‡ç­¾
    
    Returns:
        labelme shape åˆ—è¡¨
    """
    shapes = []
    
    for box in boxes:
        x1, y1, x2, y2 = box.tolist()
        
        # labelme çŸ©å½¢æ ¼å¼ï¼špoints æ˜¯ [[x1, y1], [x2, y2]]
        shape = {
            "label": label,
            "points": [[x1, y1], [x2, y2]],
            "group_id": None,
            "description": "",
            "shape_type": "rectangle",
            "flags": {},
            "mask": None,
        }
        shapes.append(shape)
    
    return shapes


def masks_to_labelme_json(
    masks: np.ndarray,
    image_path: Path,
    image: Image.Image,
    label: str,
    annotation_type: str = "segmentation",
    boxes: Optional[np.ndarray] = None,
    labels: Optional[List[str]] = None,
    scores: Optional[np.ndarray] = None,
) -> Dict:
    """
    å°†å¤šä¸ª mask æˆ– boxes è½¬æ¢ä¸º labelme æ ¼å¼çš„ JSONã€‚
    
    Args:
        masks: mask æ•°ç»„ (N, H, W) æˆ– (N, 1, H, W)ï¼Œç”¨äºåˆ†å‰²æ ¼å¼
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        image: PIL Image å¯¹è±¡
        label: ç±»åˆ«æ ‡ç­¾ï¼ˆå•ç±»åˆ«æ—¶ä½¿ç”¨ï¼Œå¦‚æœæä¾›äº† labels åˆ™å¿½ç•¥ï¼‰
        annotation_type: æ ‡æ³¨ç±»å‹ï¼Œ"segmentation"ï¼ˆåˆ†å‰²ï¼‰æˆ– "detection"ï¼ˆç›®æ ‡æ£€æµ‹ï¼‰
        boxes: è¾¹ç•Œæ¡†æ•°ç»„ (N, 4)ï¼Œæ ¼å¼ä¸º [x1, y1, x2, y2]ï¼Œç”¨äºç›®æ ‡æ£€æµ‹æ ¼å¼
        labels: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨ï¼ˆå¤šç±»åˆ«æ—¶ä½¿ç”¨ï¼‰ï¼Œé•¿åº¦åº”ä¸ masks/boxes æ•°é‡ä¸€è‡´
        scores: ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºæŒ‰åˆ†æ•°åˆ†é…ç±»åˆ«
    
    Returns:
        labelme æ ¼å¼çš„å­—å…¸
    """
    shapes = []
    
    # ç¡®å®šæ¯ä¸ªæ£€æµ‹ç»“æœçš„ç±»åˆ«æ ‡ç­¾
    num_detections = len(masks) if annotation_type == "segmentation" else (len(boxes) if boxes is not None else 0)
    
    if labels is not None and len(labels) > 0:
        # ä½¿ç”¨æä¾›çš„ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
        detection_labels = labels
    else:
        # ä½¿ç”¨å•ä¸ªç±»åˆ«æ ‡ç­¾
        detection_labels = [label] * num_detections
    
    if annotation_type == "detection":
        # ç›®æ ‡æ£€æµ‹æ ¼å¼ï¼šä½¿ç”¨è¾¹ç•Œæ¡†
        if boxes is not None and len(boxes) > 0:
            shapes = []
            for i, box in enumerate(boxes):
                x1, y1, x2, y2 = box.tolist()
                shape = {
                    "label": detection_labels[i] if i < len(detection_labels) else label,
                    "points": [[x1, y1], [x2, y2]],
                    "group_id": None,
                    "description": "",
                    "shape_type": "rectangle",
                    "flags": {},
                    "mask": None,
                }
                shapes.append(shape)
    else:
        # åˆ†å‰²æ ¼å¼ï¼šä½¿ç”¨ mask è½¬æ¢ä¸ºå¤šè¾¹å½¢
        for i, mask in enumerate(masks):
            # ç¡®ä¿ mask æ˜¯ 2D
            mask_2d = np.squeeze(mask)
            if mask_2d.ndim != 2:
                continue
            
            polygon = mask_to_polygon(mask_2d)
            if polygon is None or len(polygon) < 3:  # è‡³å°‘éœ€è¦3ä¸ªç‚¹æ‰èƒ½å½¢æˆå¤šè¾¹å½¢
                continue
            
            shape = {
                "label": detection_labels[i] if i < len(detection_labels) else label,
                "points": polygon,
                "group_id": None,
                "description": "",
                "shape_type": "polygon",
                "flags": {},
                "mask": None,
            }
            shapes.append(shape)
    
    labelme_json = {
        "version": "5.8.3",
        "flags": {},
        "shapes": shapes,
        "imagePath": image_path.name,
        "imageData": None,
        "imageHeight": image.height,
        "imageWidth": image.width,
    }
    
    return labelme_json


def save_labelme_json(
    labelme_data: Dict,
    output_dir: Path,
    stem: str,
):
    """ä¿å­˜ labelme æ ¼å¼çš„ JSON æ–‡ä»¶ã€‚"""
    labelme_dir = output_dir / "labelme_annotations"
    labelme_dir.mkdir(parents=True, exist_ok=True)
    
    json_path = labelme_dir / f"{stem}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(labelme_data, f, ensure_ascii=False, indent=2)
    
    return json_path


def main():
    input_dir = INPUT_DIR
    output_dir = OUTPUT_DIR
    overlay_dir = output_dir / "overlays"
    overlay_dir.mkdir(parents=True, exist_ok=True)

    processor = load_model(CHECKPOINT_PATH, DEVICE)

    for img_path in tqdm(list(iter_images(input_dir)), desc="Infer"):
        outputs = run_inference(processor, img_path, PROMPT, SCORE_THRESHOLD)
        image = outputs.pop("image")
        stem = img_path.stem
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if SAVE_OVERLAYS:
            visualize_and_save(image, outputs, overlay_dir / f"{stem}_overlay.png")
        
        # ä¿å­˜ mask å›¾åƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if SAVE_MASKS:
            save_masks(outputs["masks"].cpu().numpy(), output_dir, stem)
        
        # è½¬æ¢ä¸º labelme æ ¼å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if CONVERT_TO_LABELME:
            masks_np = outputs["masks"].cpu().numpy()
            boxes_np = outputs["boxes"].cpu().numpy() if "boxes" in outputs else None
            scores_np = outputs["scores"].cpu().numpy() if "scores" in outputs else None
            
            # ç¡®å®šç±»åˆ«æ ‡ç­¾
            if "LABELME_CLASS_LABELS" in globals() and len(LABELME_CLASS_LABELS) > 0:
                # å¤šç±»åˆ«æ¨¡å¼ï¼šæ ¹æ®ç­–ç•¥åˆ†é…ç±»åˆ«æ ‡ç­¾
                num_detections = len(masks_np) if LABELME_ANNOTATION_TYPE == "segmentation" else (len(boxes_np) if boxes_np is not None else 0)
                
                if LABELME_CLASS_ASSIGNMENT == "by_area":
                    if LABELME_ANNOTATION_TYPE == "segmentation":
                        # æ ¹æ® mask é¢ç§¯åˆ†ç»„åˆ†ç±»ï¼ˆé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ï¼‰
                        detection_labels = assign_labels_by_area(
                            masks_np,
                            LABELME_CLASS_LABELS,
                            tolerance=AREA_TOLERANCE
                        )
                        # æ‰“å°åˆ†ç»„ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                        groups = group_by_area(masks_np, tolerance=AREA_TOLERANCE)
                        print(f"    é¢ç§¯åˆ†ç»„åˆ†ç±»ï¼ˆå®¹å·® {AREA_TOLERANCE*100:.0f}%ï¼‰: {len(groups)} ä¸ªç»„ï¼Œå…± {num_detections} ä¸ªæ£€æµ‹")
                        for group_idx, group in enumerate(groups):
                            areas = [calculate_mask_area(masks_np[i]) for i in group]
                            min_area = min(areas)
                            max_area = max(areas)
                            avg_area = np.mean(areas)
                            label = LABELME_CLASS_LABELS[group_idx % len(LABELME_CLASS_LABELS)]
                            print(f"      ç»„ {group_idx + 1} ({label}): {len(group)} ä¸ªmaskï¼Œé¢ç§¯èŒƒå›´ [{min_area:.0f}, {max_area:.0f}]ï¼Œå¹³å‡ {avg_area:.0f} åƒç´ ")
                    elif LABELME_ANNOTATION_TYPE == "detection" and boxes_np is not None:
                        # æ ¹æ®è¾¹ç•Œæ¡†é¢ç§¯åˆ†ç»„åˆ†ç±»ï¼ˆé¢ç§¯ç›¸è¿‘çš„å½’ä¸ºåŒä¸€ç±»åˆ«ï¼‰
                        detection_labels = assign_labels_by_box_area(
                            boxes_np,
                            LABELME_CLASS_LABELS,
                            tolerance=AREA_TOLERANCE
                        )
                        # æ‰“å°åˆ†ç»„ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                        groups = group_boxes_by_area(boxes_np, tolerance=AREA_TOLERANCE)
                        print(f"    é¢ç§¯åˆ†ç»„åˆ†ç±»ï¼ˆå®¹å·® {AREA_TOLERANCE*100:.0f}%ï¼‰: {len(groups)} ä¸ªç»„ï¼Œå…± {num_detections} ä¸ªæ£€æµ‹")
                        for group_idx, group in enumerate(groups):
                            areas = [calculate_box_area(boxes_np[i]) for i in group]
                            min_area = min(areas)
                            max_area = max(areas)
                            avg_area = np.mean(areas)
                            label = LABELME_CLASS_LABELS[group_idx % len(LABELME_CLASS_LABELS)]
                            print(f"      ç»„ {group_idx + 1} ({label}): {len(group)} ä¸ªè¾¹ç•Œæ¡†ï¼Œé¢ç§¯èŒƒå›´ [{min_area:.0f}, {max_area:.0f}]ï¼Œå¹³å‡ {avg_area:.0f} åƒç´ ")
                    else:
                        # å¦‚æœæ— æ³•ä½¿ç”¨é¢ç§¯åˆ†ç»„ï¼Œå›é€€åˆ°å¾ªç¯åˆ†é…
                        detection_labels = [LABELME_CLASS_LABELS[i % len(LABELME_CLASS_LABELS)] for i in range(num_detections)]
                elif LABELME_CLASS_ASSIGNMENT == "by_score" and scores_np is not None:
                    # æ ¹æ®ç½®ä¿¡åº¦åˆ†æ•°åˆ†é…ç±»åˆ«
                    detection_labels = []
                    for score in scores_np:
                        assigned = False
                        for i, threshold in enumerate(LABELME_CLASS_SCORE_THRESHOLDS):
                            if score >= threshold:
                                detection_labels.append(LABELME_CLASS_LABELS[i])
                                assigned = True
                                break
                        if not assigned:
                            # å¦‚æœåˆ†æ•°ä½äºæ‰€æœ‰é˜ˆå€¼ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªç±»åˆ«
                            detection_labels.append(LABELME_CLASS_LABELS[-1])
                else:
                    # å¾ªç¯åˆ†é…ï¼ˆround_robinï¼‰
                    detection_labels = [LABELME_CLASS_LABELS[i % len(LABELME_CLASS_LABELS)] for i in range(num_detections)]
                
                class_label = None  # ä¸ä½¿ç”¨å•ä¸ªæ ‡ç­¾
            else:
                # å•ç±»åˆ«æ¨¡å¼ï¼šä½¿ç”¨å•ä¸ªç±»åˆ«æ ‡ç­¾
                detection_labels = None
                class_label = globals().get("LABELME_CLASS_LABEL", "object")
            
            # æ ¹æ®æ ‡æ³¨ç±»å‹å†³å®šä½¿ç”¨å“ªä¸ªæ•°æ®
            if LABELME_ANNOTATION_TYPE == "detection":
                if boxes_np is not None and len(boxes_np) > 0:
                    labelme_data = masks_to_labelme_json(
                        masks_np,  # è™½ç„¶ä¸ä½¿ç”¨ï¼Œä½†ä¿æŒæ¥å£ä¸€è‡´
                        img_path,
                        image,
                        class_label or "object",
                        annotation_type="detection",
                        boxes=boxes_np,
                        labels=detection_labels,
                        scores=scores_np,
                    )
                    json_path = save_labelme_json(labelme_data, output_dir, stem)
                    print(f"    âœ“ å·²ä¿å­˜ labelme æ£€æµ‹æ ‡æ³¨: {json_path.name} ({len(labelme_data['shapes'])} ä¸ªç›®æ ‡)")
            else:  # segmentation
                if len(masks_np) > 0:
                    labelme_data = masks_to_labelme_json(
                        masks_np,
                        img_path,
                        image,
                        class_label or "object",
                        annotation_type="segmentation",
                        labels=detection_labels,
                        scores=scores_np,
                    )
                    json_path = save_labelme_json(labelme_data, output_dir, stem)
                    print(f"    âœ“ å·²ä¿å­˜ labelme åˆ†å‰²æ ‡æ³¨: {json_path.name} ({len(labelme_data['shapes'])} ä¸ªç›®æ ‡)")

    print(f"\næ¨ç†å®Œæˆã€‚ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    if CONVERT_TO_LABELME:
        print(f"Labelme æ ‡æ³¨æ–‡ä»¶ä¿å­˜åœ¨: {output_dir / 'labelme_annotations'}")


if __name__ == "__main__":
    main()

