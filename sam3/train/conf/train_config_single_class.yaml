# @package _global_
defaults:
  - _self_

# ============================================================================
# 路径配置（硬编码）
# ============================================================================
paths:
  dataset_root: C:/Users/29923/Desktop/3d_guajia_img/guajia_aug/coco # 转换后的 COCO 数据集目录
  experiment_log_dir: D:/qianpf/code/sam3-main/experiments_guajia  # 实验输出目录
  bpe_path: assets/bpe_simple_vocab_16e6.txt.gz  # BPE 词汇表路径

# ============================================================================
# 数据集配置
# ============================================================================
dataset:
  class_name: "object"  # 类别名称（仅用于显示，不使用文本提示）
  num_classes: 1  # 单类别

# ============================================================================
# 训练参数
# ============================================================================
scratch:
  enable_segmentation: True  # 启用分割头
  use_dot_prod_scoring: True  # 使用点积评分（使用 "visual" 占位符，不依赖文本提示）
  
  # 模型参数
  d_model: 256
  resolution: 1008
  
  # 数据增强
  consistent_transform: False
  max_ann_per_img: 200
  
  # 归一化参数
  train_norm_mean: [0.5, 0.5, 0.5]
  train_norm_std: [0.5, 0.5, 0.5]
  val_norm_mean: [0.5, 0.5, 0.5]
  val_norm_std: [0.5, 0.5, 0.5]
  
  # 训练参数（小数据集优化）
  num_train_workers: 4
  num_val_workers: 2
  max_data_epochs: 20  # 保持20次数据重复，100张图片会重复15次达到1500
  target_epoch_size: 1000  # 保持1500，确保每个epoch有足够的样本
  hybrid_repeats: 1
  context_length: 2
  gather_pred_via_filesys: false
  
  # 学习率（小数据集优化：降低学习率避免过拟合）
  lr_scale: 0.05  # 从0.1降低到0.05，更保守的学习率
  lr_transformer: ${times:8e-4,${scratch.lr_scale}}
  lr_vision_backbone: ${times:2.5e-4,${scratch.lr_scale}}
  lr_language_backbone: ${times:5e-5,${scratch.lr_scale}}
  lrd_vision_backbone: 0.9
  wd: 0.15  # 从0.1增加到0.15，增强正则化防止过拟合
  scheduler_timescale: 30  # 从20增加到30，更长的学习率衰减周期
  scheduler_warmup: 30  # 从20增加到30，更长的warmup让训练更稳定
  scheduler_cooldown: 30  # 从20增加到30，更长的cooldown
  
  # 批次大小
  train_batch_size: 2
  val_batch_size: 1
  
  # Matcher 配置
  matcher:
    _target_: sam3.train.matcher.BinaryHungarianMatcherV2
    focal: true
    cost_class: 2.0
    cost_bbox: 5.0
    cost_giou: 2.0
    alpha: 0.25
    gamma: 2
    stable: False
  scale_by_find_batch_size: True
  
  # 后处理
  use_presence_eval: True
  original_box_postprocessor:
    _target_: sam3.eval.postprocessors.PostProcessImage
    max_dets_per_img: -1
    use_original_ids: true
    use_original_sizes_box: true
    use_presence: ${scratch.use_presence_eval}

# ============================================================================
# 数据变换
# ============================================================================
train_transforms:
  - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
    transforms:
      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterCrowds
      - _target_: sam3.train.transforms.point_sampling.RandomizeInputBbox
        box_noise_std: 0.15  # 从0.1增加到0.15，增强数据增强强度
        box_noise_max: 30  # 从20增加到30，增加边界框噪声范围
      - _target_: sam3.train.transforms.segmentation.DecodeRle
      - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
        sizes:
          _target_: sam3.train.transforms.basic.get_random_resize_scales
          size: ${scratch.resolution}
          min_size: 480
          rounded: false
        max_size:
          _target_: sam3.train.transforms.basic.get_random_resize_max_size
          size: ${scratch.resolution}
        square: true
        consistent_transform: ${scratch.consistent_transform}
      - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
        size: ${scratch.resolution}
        consistent_transform: ${scratch.consistent_transform}
      - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterEmptyTargets
      - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
        mean: ${scratch.train_norm_mean}
        std: ${scratch.train_norm_std}
      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterEmptyTargets
  - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
    query_filter:
      _target_: sam3.train.transforms.filter_query_transforms.FilterFindQueriesWithTooManyOut
      max_num_objects: ${scratch.max_ann_per_img}

val_transforms:
  - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
    transforms:
      - _target_: sam3.train.transforms.segmentation.DecodeRle  # 解码 RLE 格式的分割数据
      - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
        sizes: ${scratch.resolution}
        max_size:
          _target_: sam3.train.transforms.basic.get_random_resize_max_size
          size: ${scratch.resolution}
        square: true
        consistent_transform: False
      - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
      - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
        mean: ${scratch.train_norm_mean}
        std: ${scratch.train_norm_std}

# ============================================================================
# 损失函数配置
# ============================================================================
loss_config:
  _target_: sam3.train.loss.sam3_loss.Sam3LossWrapper
  matcher: ${scratch.matcher}
  o2m_weight: 2.0
  o2m_matcher:
    _target_: sam3.train.matcher.BinaryOneToManyMatcher
    alpha: 0.3
    threshold: 0.4
    topk: 4
  use_o2m_matcher_on_o2m_aux: false
  loss_fns_find:
    - _target_: sam3.train.loss.loss_fns.Boxes
      weight_dict:
        loss_bbox: 5.0
        loss_giou: 2.0
    - _target_: sam3.train.loss.loss_fns.IABCEMdetr
      weak_loss: False
      weight_dict:
        loss_ce: 20.0
        presence_loss: 20.0
      pos_weight: 10.0
      alpha: 0.25
      gamma: 2
      use_presence: True
      pos_focal: false
      pad_n_queries: 200
      pad_scale_pos: 1.0
    - _target_: sam3.train.loss.loss_fns.Masks
      focal_alpha: 0.25
      focal_gamma: 2.0
      weight_dict:
        loss_mask: 200.0
        loss_dice: 10.0
      compute_aux: false
  loss_fn_semantic_seg: null
  scale_by_find_batch_size: ${scratch.scale_by_find_batch_size}

# ============================================================================
# Trainer 配置
# ============================================================================
trainer:
  _target_: sam3.train.trainer.Trainer
  skip_saving_ckpts: false
  empty_gpu_mem_cache_after_eval: True
  skip_first_val: True
  max_epochs: 80  # 从50增加到80，小数据集需要更多轮数才能充分训练
  accelerator: cuda
  seed_value: 123
  val_epoch_freq: 2  # 从5改为2，更频繁验证以便及时发现过拟合
  mode: train
  gradient_accumulation_steps: 1  # 保持为1，当前数据加载器不支持梯度累积

  distributed:
    backend: gloo  # 使用 gloo 后端（Windows 兼容），Linux 可使用 nccl
    find_unused_parameters: True
    gradient_as_bucket_view: True

  loss:
    all: ${loss_config}
    default:
      _target_: sam3.train.loss.sam3_loss.DummyLoss

  data:
    train:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        img_folder: ${paths.dataset_root}/train/images/
        ann_file: ${paths.dataset_root}/train/annotations.json
        transforms: ${train_transforms}
        load_segmentation: ${scratch.enable_segmentation}
        max_ann_per_img: ${scratch.max_ann_per_img}
        multiplier: 1
        max_train_queries: 50000
        max_val_queries: 50000
        training: true
        use_caching: False
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          prompts: '[{"id": 1, "name": "visual"}]'  # 使用 "visual" 占位符，不依赖文本提示
          include_negatives: false
          category_chunk_size: 1
          _partial_: true
      shuffle: True
      batch_size: ${scratch.train_batch_size}
      num_workers: ${scratch.num_train_workers}
      pin_memory: True
      drop_last: True
      collate_fn:
        _target_: sam3.train.data.collator.collate_fn_api
        _partial_: true
        repeats: ${scratch.hybrid_repeats}
        dict_key: all
        with_seg_masks: ${scratch.enable_segmentation}

    val:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        load_segmentation: ${scratch.enable_segmentation}  # 启用分割数据加载
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          prompts: '[{"id": 1, "name": "visual"}]'  # 使用 "visual" 占位符，不依赖文本提示
          include_negatives: false
          category_chunk_size: 1
          _partial_: true
        img_folder: ${paths.dataset_root}/val/images/
        ann_file: ${paths.dataset_root}/val/annotations.json
        transforms: ${val_transforms}
        max_ann_per_img: 100000
        multiplier: 1
        training: false
      shuffle: False
      batch_size: ${scratch.val_batch_size}
      num_workers: ${scratch.num_val_workers}
      pin_memory: True
      drop_last: False
      collate_fn:
        _target_: sam3.train.data.collator.collate_fn_api
        _partial_: true
        repeats: ${scratch.hybrid_repeats}
        dict_key: all
        with_seg_masks: ${scratch.enable_segmentation}  # 启用分割掩码

  model:
    _target_: sam3.model_builder.build_sam3_image_model
    bpe_path: ${paths.bpe_path}
    device: cpus
    eval_mode: false
    enable_segmentation: ${scratch.enable_segmentation}
    checkpoint_path: D:/qianpf/code/sam3-main/model/sam3/sam3.pt  # 使用本地预训练模型
    load_from_HF: false  # 禁用从 HuggingFace 下载

  meters:
    val:
      all:  # 修改为 'all' 以匹配验证数据集的 dict_key
        detection:
          _target_: sam3.eval.coco_writer.PredictionDumper
          iou_type: "bbox"
          dump_dir: ${launcher.experiment_log_dir}/dumps/val
          merge_predictions: True
          postprocessor: ${scratch.original_box_postprocessor}
          gather_pred_via_filesys: ${scratch.gather_pred_via_filesys}
          maxdets: 100
          pred_file_evaluators:
            - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
              gt_path: ${paths.dataset_root}/val/annotations.json
              tide: False
              iou_type: "bbox"

  optim:
    amp:
      enabled: True
      amp_dtype: bfloat16

    optimizer:
      _target_: torch.optim.AdamW

    gradient_clip:
      _target_: sam3.train.optim.optimizer.GradientClipper
      max_norm: 0.1
      norm_type: 2

    param_group_modifiers:
      - _target_: sam3.train.optim.optimizer.layer_decay_param_modifier
        _partial_: True
        layer_decay_value: ${scratch.lrd_vision_backbone}
        apply_to: 'backbone.vision_backbone.trunk'
        overrides:
          - pattern: '*pos_embed*'
            value: 1.0

    options:
      lr:
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_transformer}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_vision_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - 'backbone.vision_backbone.*'
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_language_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - 'backbone.language_backbone.*'

      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: ${scratch.wd}
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*bias*'
          module_cls_names: ['torch.nn.LayerNorm']

  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 5  # 每10个epoch保存一次权重，减少存储空间占用

  logging:
    tensorboard_writer:
      _target_: sam3.train.utils.logger.make_tensorboard_logger
      log_dir: ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      should_log: True
    wandb_writer: null
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10

# ============================================================================
# Launcher 配置
# ============================================================================
launcher:
  num_nodes: 1
  gpus_per_node: 1  # 根据你的 GPU 数量修改
  experiment_log_dir: ${paths.experiment_log_dir}
  multiprocessing_context: forkserver

# ============================================================================
# Submitit 配置（用于分布式训练和集群调度）
# ============================================================================
submitit:
  account: null  # SLURM 账户（集群训练时需要）
  partition: null  # SLURM 分区
  qos: null  # SLURM QoS
  timeout_hour: 72  # 训练超时时间（小时）
  use_cluster: False  # 本地训练设置为 False，集群训练设置为 True
  cpus_per_task: 10  # 每个任务的 CPU 数量
  port_range: [10000, 65000]  # 分布式训练端口范围
  constraint: null  # SLURM 约束条件

