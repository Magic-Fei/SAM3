"""
è®­ç»ƒé’©å­ï¼šè‡ªåŠ¨ä¿å­˜æ¨ç†æ¨¡å‹ï¼ˆFP16å‹ç¼©ç‰ˆæœ¬ï¼‰

åœ¨æ¯æ¬¡ä¿å­˜checkpointæ—¶ï¼Œè‡ªåŠ¨æå–æ¨¡å‹æƒé‡å¹¶è½¬æ¢ä¸ºFP16ï¼Œ
ç”Ÿæˆä¸€ä¸ªé€‚åˆæ¨ç†çš„è½»é‡çº§æ¨¡å‹æ–‡ä»¶ã€‚
"""

import os
import torch
from pathlib import Path


def save_inference_model_hook(trainer, epoch):
    """
    åœ¨ä¿å­˜checkpointåè°ƒç”¨ï¼Œè‡ªåŠ¨ç”Ÿæˆæ¨ç†æ¨¡å‹
    
    Args:
        trainer: è®­ç»ƒå™¨å®ä¾‹
        epoch: å½“å‰epoch
    """
    # è·å–æœ€æ–°ä¿å­˜çš„checkpointè·¯å¾„
    checkpoint_dir = Path(trainer.checkpoint_conf.save_dir)
    checkpoint_path = checkpoint_dir / f"checkpoint_epoch_{epoch}.pth"
    
    if not checkpoint_path.exists():
        return
    
    # åˆ›å»ºinferenceæ¨¡å‹ä¿å­˜ç›®å½•
    inference_dir = checkpoint_dir / "inference_models"
    inference_dir.mkdir(exist_ok=True)
    
    # åŠ è½½å®Œæ•´checkpoint
    print(f"\nğŸ”„ æ­£åœ¨ç”Ÿæˆæ¨ç†æ¨¡å‹ (epoch {epoch})...")
    checkpoint = torch.load(checkpoint_path, map_location="cpu")
    
    # æå–æ¨¡å‹æƒé‡
    if "model" in checkpoint:
        model_state = checkpoint["model"]
    elif "state_dict" in checkpoint:
        model_state = checkpoint["state_dict"]
    else:
        print("âŒ æ— æ³•æ‰¾åˆ°æ¨¡å‹æƒé‡ï¼Œè·³è¿‡æ¨ç†æ¨¡å‹ç”Ÿæˆ")
        return
    
    # è½¬æ¢ä¸ºFP16
    model_state_fp16 = {
        k: v.half() if v.dtype == torch.float32 else v
        for k, v in model_state.items()
    }
    
    # ä¿å­˜æ¨ç†æ¨¡å‹
    inference_path = inference_dir / f"model_epoch_{epoch}_fp16.pth"
    torch.save(model_state_fp16, inference_path)
    
    # è®¡ç®—å¤§å°
    full_size = os.path.getsize(checkpoint_path) / (1024**3)
    inference_size = os.path.getsize(inference_path) / (1024**3)
    
    print(f"âœ… æ¨ç†æ¨¡å‹å·²ä¿å­˜:")
    print(f"   å®Œæ•´checkpoint: {full_size:.2f} GB")
    print(f"   æ¨ç†æ¨¡å‹(FP16): {inference_size:.2f} GB")
    print(f"   ä¿å­˜è·¯å¾„: {inference_path}")
    print(f"   å‹ç¼©ç‡: {(1 - inference_size/full_size)*100:.1f}%\n")
    
    # å¯é€‰ï¼šä¿å­˜ä¸€ä¸ª"æœ€æ–°"é“¾æ¥
    latest_path = inference_dir / "model_latest_fp16.pth"
    if latest_path.exists():
        latest_path.unlink()
    
    # åœ¨Windowsä¸Šåˆ›å»ºå‰¯æœ¬ï¼Œåœ¨Linuxä¸Šåˆ›å»ºç¬¦å·é“¾æ¥
    try:
        os.symlink(inference_path, latest_path)
    except (OSError, NotImplementedError):
        # Windowsæˆ–ä¸æ”¯æŒç¬¦å·é“¾æ¥çš„ç³»ç»Ÿ
        import shutil
        shutil.copy2(inference_path, latest_path)
    
    print(f"   æœ€æ–°æ¨¡å‹: {latest_path}")


class InferenceModelSaver:
    """
    è®­ç»ƒé’©å­ç±»ï¼šåœ¨æ¯æ¬¡ä¿å­˜checkpointæ—¶è‡ªåŠ¨ç”Ÿæˆæ¨ç†æ¨¡å‹
    
    ç”¨æ³•ï¼ˆåœ¨trainerä¸­ï¼‰ï¼š
        from sam3.train.hooks.save_inference_model import InferenceModelSaver
        trainer.register_hook(InferenceModelSaver())
    """
    
    def __init__(self, save_fp16=True, save_fp32=False):
        """
        Args:
            save_fp16: æ˜¯å¦ä¿å­˜FP16ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
            save_fp32: æ˜¯å¦ä¿å­˜FP32ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
        """
        self.save_fp16 = save_fp16
        self.save_fp32 = save_fp32
    
    def after_save_checkpoint(self, trainer, epoch):
        """åœ¨ä¿å­˜checkpointåè‡ªåŠ¨è°ƒç”¨"""
        save_inference_model_hook(trainer, epoch)

