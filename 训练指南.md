# SAM3 单类别分割数据集训练指南

## 步骤 1: 转换数据集格式

### 1.1 安装依赖

```bash
pip install labelme pycocotools pillow numpy tqdm
```

### 1.2 准备 Labelme 数据集

确保你的数据集结构如下：
```
labelme_dataset/
├── image1.jpg
├── image1.json
├── image2.jpg
├── image2.json
└── ...
```

### 1.3 运行转换脚本

```bash
python labelme_to_coco.py \
    --labelme_dir /path/to/labelme_dataset \
    --output_dir /path/to/coco_dataset \
    --class_name "your_class_name" \
    --train_split 0.8
```

**参数说明：**
- `--labelme_dir`: Labelme 标注文件目录（包含 JSON 和图像）
- `--output_dir`: 输出 COCO 格式数据集目录
- `--class_name`: 类别名称（例如: "person", "car", "dog"）
- `--train_split`: 训练集比例（默认 0.8，即 80% 训练，20% 验证）

**示例：**
```bash
python labelme_to_coco.py \
    --labelme_dir ./my_labelme_data \
    --output_dir ./coco_dataset \
    --class_name "object" \
    --train_split 0.8
```

### 1.4 转换后的数据集结构

```
coco_dataset/
├── train/
│   ├── images/
│   │   ├── image1.jpg
│   │   ├── image2.jpg
│   │   └── ...
│   └── annotations.json
└── val/
    ├── images/
    │   ├── image3.jpg
    │   ├── image4.jpg
    │   └── ...
    └── annotations.json
```

## 步骤 2: 配置训练参数

### 2.1 修改配置文件

编辑 `train_config_single_class.yaml`，修改以下路径：

```yaml
paths:
  dataset_root: /path/to/coco_dataset  # 修改为你的数据集路径
  experiment_log_dir: /path/to/experiments  # 修改为实验输出目录
  bpe_path: assets/bpe_simple_vocab_16e6.txt.gz  # BPE 词汇表路径

dataset:
  class_name: "your_class_name"  # 修改为你的类别名称
```

### 2.2 调整训练参数（可选）

根据你的 GPU 内存和数据集大小，可以调整：

```yaml
scratch:
  train_batch_size: 2  # 如果 GPU 内存不足，可以改为 1
  val_batch_size: 1
  num_train_workers: 4  # 数据加载线程数
  resolution: 1008  # 图像分辨率，可以降低以节省内存
  max_epochs: 50  # 训练轮数
```

## 步骤 3: 开始训练

### 3.1 单 GPU 训练

```bash
python sam3/train/train.py -c train_config_single_class.yaml
```

### 3.2 多 GPU 训练

如果有多张 GPU，修改配置文件中的 `gpus_per_node`：

```yaml
launcher:
  gpus_per_node: 2  # 修改为你的 GPU 数量
```

然后运行：
```bash
python sam3/train/train.py -c train_config_single_class.yaml
```

### 3.3 从检查点恢复训练

如果训练中断，可以从检查点恢复：

```yaml
trainer:
  model:
    checkpoint_path: /path/to/checkpoint.pt  # 指定检查点路径
```

## 步骤 4: 监控训练

### 4.1 TensorBoard

训练过程中可以使用 TensorBoard 监控：

```bash
tensorboard --logdir /path/to/experiments/tensorboard
```

### 4.2 查看日志

训练日志保存在：
```
/path/to/experiments/logs/
```

## 步骤 5: 验证训练结果

训练完成后，检查点保存在：
```
/path/to/experiments/checkpoints/
```

验证结果保存在：
```
/path/to/experiments/dumps/val/
```

## 常见问题

### Q1: 内存不足 (OOM)

**解决方案：**
1. 减小 `train_batch_size`（改为 1）
2. 降低 `resolution`（改为 800 或更小）
3. 减小 `num_train_workers`

### Q2: 训练速度慢

**解决方案：**
1. 增加 `num_train_workers`
2. 使用多 GPU 训练
3. 减小 `resolution`

### Q3: 转换脚本报错

**可能原因：**
1. Labelme JSON 格式不正确
2. 图像路径找不到
3. 多边形标注格式问题

**解决方案：**
- 检查 Labelme JSON 文件格式
- 确保图像文件存在
- 确保标注是多边形格式

### Q4: 类别名称不匹配

**解决方案：**
确保配置文件中的 `class_name` 与转换脚本中使用的名称一致。

## 推理使用

训练完成后，可以使用训练好的模型进行推理：

```python
import torch
from PIL import Image
from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor

# 加载模型
model = build_sam3_image_model(
    checkpoint_path="path/to/checkpoint.pt",
    load_from_HF=False,
    enable_segmentation=True,
)

processor = Sam3Processor(model)

# 加载图像
image = Image.open("test_image.jpg")
inference_state = processor.set_image(image)

# 使用类别名称作为提示词
output = processor.set_text_prompt(
    state=inference_state, 
    prompt="your_class_name"  # 与训练时使用的类别名称一致
)

# 获取结果
masks = output["masks"]
boxes = output["boxes"]
scores = output["scores"]
```

## 完整示例命令

```bash
# 1. 转换数据集
python labelme_to_coco.py \
    --labelme_dir ./my_labelme_data \
    --output_dir ./coco_dataset \
    --class_name "object" \
    --train_split 0.8

# 2. 修改配置文件中的路径

# 3. 开始训练
python sam3/train/train.py -c train_config_single_class.yaml
```

## 注意事项

1. **类别名称**: 训练和推理时使用的类别名称必须一致
2. **图像格式**: 支持常见图像格式（jpg, png 等）
3. **标注格式**: 只支持多边形标注，不支持矩形或其他形状
4. **预训练模型**: 首次训练会自动从 HuggingFace 下载预训练模型，需要网络连接
5. **GPU 要求**: 建议使用至少 16GB 显存的 GPU

