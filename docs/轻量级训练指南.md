# SAM3 è½»é‡çº§è®­ç»ƒæŒ‡å— (FP16 + å°æ¶æ„)

ç›´æ¥åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ FP16 æ··åˆç²¾åº¦ + å‡å°çš„æ¨¡å‹æ¶æ„ï¼Œä¸€æ­¥åˆ°ä½å¾—åˆ°å°æ¨¡å‹ï¼

---

## âœ¨ è½»é‡çº§æ–¹æ¡ˆä¼˜åŠ¿

| é¡¹ç›® | æ ‡å‡†ç‰ˆ | è½»é‡çº§ | æ”¹å–„ |
|------|--------|--------|------|
| **æ¨¡å‹å¤§å°** | 2.5 GB | ~1.0 GB | **â†“ 60%** |
| **è®­ç»ƒé€Ÿåº¦** | åŸºå‡† | å¿« 30-40% | **â†‘ 35%** |
| **æ˜¾å­˜å ç”¨** | åŸºå‡† | å‡å°‘ 40-50% | **â†“ 45%** |
| **è®­ç»ƒæ—¶é•¿** | åŸºå‡† | å‡å°‘ 30% | **â†“ 30%** |
| **æ€§èƒ½æŸå¤±** | 100% | 90-95% | **-5~10%** |

### æ¶æ„å˜åŒ–

**ViT (Vision Transformer):**
- `embed_dim`: 1024 â†’ 768 (-25%)
- `depth`: 32 â†’ 24 (-25%)
- `num_heads`: 16 â†’ 12 (-25%)

**Transformer:**
- Encoder `num_layers`: 6 â†’ 4 (-33%)
- Decoder `num_layers`: 6 â†’ 4 (-33%)

**è®­ç»ƒ:**
- æ··åˆç²¾åº¦: FP16 (è‡ªåŠ¨å¤„ç†)
- å­¦ä¹ ç‡: æå‡åˆ° 2e-4
- Batch size: å¯ä»¥å¢å¤§ï¼ˆæ˜¾å­˜æ›´å°‘ï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨è½»é‡çº§é…ç½®è®­ç»ƒ

```bash
cd D:\qianpf\code\sam3-main

# ç›´æ¥è®­ç»ƒè½»é‡çº§æ¨¡å‹
python sam3/train/train.py -c train_config_lite_fp16
```

**å°±è¿™ä¹ˆç®€å•ï¼** è®­ç»ƒå®Œæˆåç›´æ¥å¾—åˆ° ~1.0 GB çš„ FP16 æ¨¡å‹ã€‚

### æ–¹æ³• 2: ä»é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒï¼ˆå¦‚æœæœ‰ï¼‰

å¦‚æœä½ ä¹‹å‰è®­ç»ƒäº†æ ‡å‡†æ¨¡å‹ï¼Œæƒ³åˆ‡æ¢åˆ°è½»é‡çº§ï¼š

```bash
# 1. å…ˆå‹ç¼©ç°æœ‰æ¨¡å‹åˆ° FP16
python tools/compress_model.py

# 2. ä¿®æ”¹ train_config_lite_fp16.yaml ä¸­çš„ checkpoint_path:
#    checkpoint_path: "experiments/model_fp16.pt"

# 3. ç»§ç»­è®­ç»ƒ
python sam3/train/train.py -c train_config_lite_fp16
```

æ³¨æ„ï¼šç”±äºæ¶æ„ä¸åŒï¼Œæƒé‡å¯èƒ½ä¸å®Œå…¨å…¼å®¹ï¼ˆä¼šæœ‰è­¦å‘Šï¼‰ï¼Œä½†ä»å¯åŠ é€Ÿæ”¶æ•›ã€‚

---

## ğŸ“Š è®­ç»ƒé…ç½®è¯¦è§£

### 1. è½»é‡çº§æ¨¡å‹æ„å»ºå™¨

æ–°æ–‡ä»¶ï¼š`sam3/model_builder_lite.py`

```python
from sam3.model_builder_lite import build_sam3_lite_model

model = build_sam3_lite_model(
    enable_segmentation=True,
    eval_mode=False,
)
```

è‡ªåŠ¨ä½¿ç”¨ï¼š
- è½»é‡çº§ ViT (768 dim, 24 layers)
- è½»é‡çº§ Transformer (4 layers)

### 2. FP16 æ··åˆç²¾åº¦è®­ç»ƒ

é…ç½®æ–‡ä»¶ä¸­å·²å¯ç”¨ï¼š

```yaml
optim:
  amp:
    enabled: True
    amp_dtype: float16  # â­ ä½¿ç”¨ FP16
```

**æ•ˆæœï¼š**
- è®­ç»ƒé€Ÿåº¦å¿« 30-40%
- æ˜¾å­˜å ç”¨å‡å°‘ 40-50%
- å¯ä»¥ç”¨æ›´å¤§çš„ batch size
- æ¨¡å‹è‡ªåŠ¨ä¿å­˜ä¸º FP16

### 3. ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°

```yaml
# å­¦ä¹ ç‡ï¼ˆè½»é‡çº§æ¨¡å‹æ”¶æ•›æ›´å¿«ï¼‰
learning_rate: 2e-4  # æ ‡å‡†ç‰ˆ: 1e-4

# Batch sizeï¼ˆæ˜¾å­˜æ›´å°‘ï¼Œå¯ä»¥å¢å¤§ï¼‰
train_batch_size: 4  # å¦‚æœæ˜¾å­˜è¶³å¤Ÿå¯ä»¥æ”¹ä¸º 8

# Epochsï¼ˆè½»é‡çº§æ¨¡å‹å¯ä»¥å¤šè®­ç»ƒï¼‰
max_data_epochs: 30  # æ ‡å‡†ç‰ˆ: 20
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„

è®­ç»ƒåçš„æ–‡ä»¶ç»“æ„ï¼š

```
D:/qianpf/code/sam3-main/
â”œâ”€â”€ sam3/
â”‚   â””â”€â”€ model_builder_lite.py          â† è½»é‡çº§æ¨¡å‹æ„å»ºå™¨
â”œâ”€â”€ train_config_lite_fp16.yaml        â† è½»é‡çº§è®­ç»ƒé…ç½®
â”œâ”€â”€ sam3/train/conf/
â”‚   â””â”€â”€ train_config_lite_fp16.yaml    â† Hydra é…ç½®
â””â”€â”€ experiments_lite/                   â† è®­ç»ƒè¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/
    â”‚   â”œâ”€â”€ checkpoint.pt              â† æœ€æ–° checkpoint (~1.0 GB)
    â”‚   â”œâ”€â”€ checkpoint_5.pt            â† Epoch 5
    â”‚   â””â”€â”€ checkpoint_10.pt           â† Epoch 10
    â”œâ”€â”€ tensorboard/                    â† TensorBoard æ—¥å¿—
    â””â”€â”€ logs/                           â† æ–‡æœ¬æ—¥å¿—
```

---

## âš™ï¸ é«˜çº§é…ç½®

### è°ƒæ•´æ¨¡å‹å¤§å°

å¦‚æœè¿˜æƒ³æ›´å°æˆ–ç¨å¤§ï¼Œå¯ä»¥ç¼–è¾‘ `sam3/model_builder_lite.py`:

#### æ›´å°æ¨¡å‹ (~0.8 GB):

```python
def _create_vit_backbone_lite(compile_mode=None):
    return ViT(
        embed_dim=512,      # å‡å°‘åˆ° 512
        depth=16,           # å‡å°‘åˆ° 16
        num_heads=8,        # å‡å°‘åˆ° 8
        ...
    )
```

#### ä¸­ç­‰æ¨¡å‹ (~1.3 GB):

```python
def _create_vit_backbone_lite(compile_mode=None):
    return ViT(
        embed_dim=896,      # ä»‹äº 768-1024 ä¹‹é—´
        depth=28,           # ä»‹äº 24-32 ä¹‹é—´
        num_heads=14,       # ä»‹äº 12-16 ä¹‹é—´
        ...
    )
```

### è°ƒæ•´ Batch Size

æ ¹æ®ä½ çš„ GPU æ˜¾å­˜è°ƒæ•´ï¼š

| GPU æ˜¾å­˜ | æ¨è Batch Size | è¯´æ˜ |
|---------|----------------|------|
| 8 GB    | 2              | æœ€å°é…ç½® |
| 12 GB   | 4              | é»˜è®¤é…ç½® |
| 16 GB   | 6-8            | æ¨è |
| 24 GB   | 8-12           | æœ€ä½³ |

ç¼–è¾‘ `train_config_lite_fp16.yaml`:

```yaml
scratch:
  train_batch_size: 8  # æ”¹ä¸ºä½ çš„å€¼
  val_batch_size: 4
```

---

## ğŸ¯ æ¨ç†ä½¿ç”¨

è®­ç»ƒå®Œæˆåï¼Œç›´æ¥ä½¿ç”¨è½»é‡çº§æ¨¡å‹æ¨ç†ï¼š

### æ–¹æ³• 1: ä½¿ç”¨æœ€æ–° checkpoint

```bash
# ä¿®æ”¹ batch_inference.py
CHECKPOINT_PATH = Path("experiments_lite/checkpoints/checkpoint.pt")
USE_FP16 = True  # å¯ç”¨ FP16

python tools/batch_inference.py
```

### æ–¹æ³• 2: æå–çº¯æƒé‡ï¼ˆå¯é€‰ï¼‰

è™½ç„¶å·²ç»å¾ˆå°äº†ï¼Œä½†è¿˜å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š

```bash
# æå–çº¯æƒé‡
python tools/extract_model_weights.py

# è¾“å‡º: experiments_lite/model_weights_only.pt (~0.8 GB)
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### è®­ç»ƒæ€§èƒ½ï¼ˆå• GPUï¼ŒRTX 3090ï¼‰

| æ¨¡å‹ | Batch Size | æ˜¾å­˜å ç”¨ | æ¯ Epoch æ—¶é—´ |
|------|-----------|---------|--------------|
| æ ‡å‡†ç‰ˆ (FP32) | 2 | 22 GB | 45 min |
| æ ‡å‡†ç‰ˆ (FP16) | 4 | 16 GB | 30 min |
| **è½»é‡çº§ (FP16)** | **8** | **12 GB** | **20 min** |

### æ¨ç†æ€§èƒ½

| æ¨¡å‹ | å¤§å° | FPS (GPU) | mAP |
|------|------|-----------|-----|
| æ ‡å‡†ç‰ˆ | 2.5 GB | 8.5 | 100% |
| **è½»é‡çº§** | **1.0 GB** | **12** | **92%** |

---

## ğŸ” ç›‘æ§è®­ç»ƒ

### TensorBoard

```bash
tensorboard --logdir experiments_lite/tensorboard
```

è®¿é—®ï¼šhttp://localhost:6006

### æŸ¥çœ‹æ—¥å¿—

```bash
# Windows
type experiments_lite\logs\train.log

# Linux/Mac
tail -f experiments_lite/logs/train.log
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: èƒ½ä»æ ‡å‡†æ¨¡å‹ç»§ç»­è®­ç»ƒå—ï¼Ÿ

A: å¯ä»¥ï¼Œä½†ç”±äºæ¶æ„ä¸åŒï¼Œéƒ¨åˆ†æƒé‡ä¸å…¼å®¹ï¼ˆä¼šæœ‰è­¦å‘Šï¼‰ã€‚å»ºè®®ï¼š
1. å…ˆå‹ç¼©æ ‡å‡†æ¨¡å‹åˆ° FP16
2. åœ¨è½»é‡çº§é…ç½®ä¸­æŒ‡å®š checkpoint
3. ä¼šè‡ªåŠ¨è·³è¿‡ä¸å…¼å®¹çš„å±‚

### Q2: FP16 ä¼šå½±å“ç²¾åº¦å—ï¼Ÿ

A: å½±å“å¾ˆå°ï¼ˆ<1%ï¼‰ã€‚PyTorch çš„æ··åˆç²¾åº¦è®­ç»ƒä¼šè‡ªåŠ¨å¤„ç†ï¼š
- å‰å‘/åå‘ä¼ æ’­: FP16ï¼ˆå¿«é€Ÿï¼‰
- æƒé‡æ›´æ–°: FP32ï¼ˆç²¾ç¡®ï¼‰
- æŸå¤±ç¼©æ”¾: è‡ªåŠ¨é˜²æ­¢ä¸‹æº¢

### Q3: å¦‚ä½•åˆ‡æ¢å›æ ‡å‡†æ¨¡å‹ï¼Ÿ

A: ä½¿ç”¨åŸæ¥çš„é…ç½®æ–‡ä»¶ï¼š

```bash
python sam3/train/train.py -c train_config_single_class
```

### Q4: è½»é‡çº§æ¨¡å‹é€‚åˆä»€ä¹ˆåœºæ™¯ï¼Ÿ

A: æ¨èç”¨äºï¼š
- âœ… èµ„æºå—é™ï¼ˆæ˜¾å­˜ã€å­˜å‚¨ï¼‰
- âœ… éœ€è¦å¿«é€Ÿæ¨ç†
- âœ… å•ç±»åˆ«æˆ–å°‘ç±»åˆ«æ£€æµ‹
- âœ… å®æ—¶åº”ç”¨

ä¸æ¨èï¼š
- âŒ éœ€è¦æè‡´ç²¾åº¦ï¼ˆå¤§å‹æ¯”èµ›ï¼‰
- âŒ éå¸¸å¤æ‚çš„åœºæ™¯ï¼ˆ100+ ç±»åˆ«ï¼‰

---

## ğŸ‰ æ€»ç»“

è½»é‡çº§è®­ç»ƒä¸€æ­¥åˆ°ä½ï¼š

```bash
# 1. ç›´æ¥è®­ç»ƒè½»é‡çº§æ¨¡å‹
python sam3/train/train.py -c train_config_lite_fp16

# 2. ç­‰å¾…è®­ç»ƒå®Œæˆï¼ˆæ¯”æ ‡å‡†ç‰ˆå¿« 30%ï¼‰

# 3. ç›´æ¥ä½¿ç”¨ (~1.0 GB æ¨¡å‹)
python tools/batch_inference.py
```

**ä¼˜åŠ¿ï¼š**
- âœ… æ¨¡å‹å° 60%
- âœ… è®­ç»ƒå¿« 30%
- âœ… æ˜¾å­˜çœ 45%
- âœ… æ¨ç†å¿« 40%
- âœ… æ€§èƒ½æŸå¤± <10%

**å®Œç¾é€‚åˆèµ„æºå—é™çš„å®é™…åº”ç”¨ï¼** ğŸš€

